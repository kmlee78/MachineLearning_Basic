{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST데이터 셋 가지고 오기\n",
    "dataset = pd.read_csv('../data/MNIST_preprocessed.csv', sep=',', header=None).values\n",
    "\n",
    "# 입력 변수인 픽셀 데이터와 목표 변수인 실제 숫자 데이터로 셋 나누기\n",
    "X = dataset[:, 0:784]\n",
    "Y = dataset[:, 784:]\n",
    "\n",
    "# training, testing 데이터 셋 나누기\n",
    "X_train, X_test = X[0:250,], X[250:,]\n",
    "Y_train, Y_test = Y[0:250,], Y[250:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망의 가중치와 편향을 초기화 해주는 함수\n",
    "# 그 초기화된 값들을 파이썬 사전에 저장하여 리턴 해준다\n",
    "\n",
    "def initialize_parameters(nodes_per_layer):\n",
    "    L = len(nodes_per_layer) - 1  # 층 개수\n",
    "    parameters = {}\n",
    "    \n",
    "    # 1층 부터 L 층까지 돌면서 가중치와 편향 초기화\n",
    "    # np.random.randn(a) -> 크기 a의 임의의 배열 생성\n",
    "    # np.random.randn(a, b) -> 크기 a X b의 임의의 배열 생성\n",
    "    for l in range(1, L+1):\n",
    "        parameters['W' + str(l)] = np.random.randn(nodes_per_layer[l], nodes_per_layer[l-1]) * np.sqrt(1. / nodes_per_layer[l])\n",
    "        parameters['b' + str(l)] = np.random.randn(nodes_per_layer[l]) * np.sqrt(1. / nodes_per_layer[l])\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순전파 함수\n",
    "\n",
    "def feed_forward(x, parameters):\n",
    "    cache = {'a0': x}  # 0 번째 층 출력\n",
    "    L = len(parameters) // 2  # 층 수 \n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        # 전 층 뉴런의 출력, 현재 층 뉴런들의 가중치, 편향 데이터를 가지고 온다\n",
    "        a_prev = cache['a' + str(l-1)]\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        \n",
    "        # 가지고 온 데이터로 z와 a를 계산한다\n",
    "        # z[l] = W[l]a[l-1] + b[l]\n",
    "        # a[l] = sig(z[l])\n",
    "        z = W @ a_prev + b\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        # 결과 값을 캐시에 저장\n",
    "        cache['z' + str(l)] = z\n",
    "        cache['a' + str(l)] = a\n",
    "                \n",
    "    return a, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45375375, 0.46105872, 0.27746944, 0.66384021, 0.48595997,\n",
       "       0.51041694, 0.31788025, 0.75667466, 0.8739425 , 0.43569649])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 층에 있는 뉴런들의 개수를 저장해 둔 배열\n",
    "neurons_per_layer = [784, 128, 64, 10]\n",
    "\n",
    "# 우선 층의 개수와 뉴런들의 개수에 대한 정보를 담고 있는 배열로 임의의 가중치 및 편향 사전을 만든다\n",
    "parameters = initialize_parameters(neurons_per_layer)\n",
    "\n",
    "# 그리고 그 사전으로 데이터 하나에 대해 순전파 실행\n",
    "feed_forward(X_train[0], parameters)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
