{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "df = pd.read_csv('../data/ETFs_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"기술지표: 이동평균, 거래량 이동 평균, rsi 등\"\"\"\n",
    "\n",
    "def moving_average(df, n):\n",
    "    MA = pd.Series(df['CLOSE_SPY'].rolling(n, min_periods=n).mean(), name = 'MA_'+str(n))\n",
    "    df = df.join(MA)\n",
    "    return df\n",
    "\n",
    "def volume_moving_average(df, n):\n",
    "    VMA = pd.Series(df['VOLUME'].rolling(n, min_periods=n).mean(), name = 'VMA_'+str(n))\n",
    "    df = df.join(VMA)\n",
    "    return df\n",
    "\n",
    "def relative_strength_index(df, n):\n",
    "    i = 0\n",
    "    UpI = [0]\n",
    "    DoI = [0]\n",
    "    while i+1 <= df.index[-1]:\n",
    "        UpMove = df.loc[i+1, 'HIGH'] - df.loc[i, 'HIGH']\n",
    "        DoMove = df.loc[i, 'LOW'] - df.loc[i+1, 'LOW']\n",
    "        if UpMove > DoMove and UpMove > 0:\n",
    "            UpD = UpMove\n",
    "        else:\n",
    "            UpD = 0\n",
    "        UpI.append(UpD)\n",
    "        if DoMove > UpMove and DoMove > 0:\n",
    "            DoD = DoMove\n",
    "        else:\n",
    "            DoD = 0\n",
    "        DoI.append(DoD)\n",
    "        i = i + 1\n",
    "    UpI = pd.Series(UpI)\n",
    "    DoI = pd.Series(DoI)\n",
    "    PosDI = pd.Series(UpI.ewm(span=n, min_periods=n).mean())   # 지수 이동 평균\n",
    "    NegDI = pd.Series(DoI.ewm(span=n, min_periods=n).mean())\n",
    "    RSI = pd.Series(PosDI / (PosDI + NegDI), name = 'RSI_'+str(n))\n",
    "    df = df.join(RSI)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLOSE_GLD</th>\n",
       "      <th>CLOSE_FXY</th>\n",
       "      <th>CLOSE_T10Y2Y</th>\n",
       "      <th>CLOSE_TED</th>\n",
       "      <th>CLOSE_USO</th>\n",
       "      <th>CLOSE_UUP</th>\n",
       "      <th>CLOSE_VIX</th>\n",
       "      <th>CLOSE_VWO</th>\n",
       "      <th>MA_45</th>\n",
       "      <th>VMA_45</th>\n",
       "      <th>RSI_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-04-27</th>\n",
       "      <td>67.56</td>\n",
       "      <td>83.7300</td>\n",
       "      <td>2.4474</td>\n",
       "      <td>0.55</td>\n",
       "      <td>51.84</td>\n",
       "      <td>24.54</td>\n",
       "      <td>12.45</td>\n",
       "      <td>41.750</td>\n",
       "      <td>143.551556</td>\n",
       "      <td>1.106696e+08</td>\n",
       "      <td>0.670018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-30</th>\n",
       "      <td>67.09</td>\n",
       "      <td>83.7166</td>\n",
       "      <td>2.4361</td>\n",
       "      <td>0.57</td>\n",
       "      <td>51.24</td>\n",
       "      <td>24.49</td>\n",
       "      <td>14.22</td>\n",
       "      <td>40.935</td>\n",
       "      <td>143.601556</td>\n",
       "      <td>1.116466e+08</td>\n",
       "      <td>0.531751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-05-02</th>\n",
       "      <td>66.66</td>\n",
       "      <td>83.3800</td>\n",
       "      <td>2.4366</td>\n",
       "      <td>0.59</td>\n",
       "      <td>49.59</td>\n",
       "      <td>24.66</td>\n",
       "      <td>13.08</td>\n",
       "      <td>42.020</td>\n",
       "      <td>143.680667</td>\n",
       "      <td>1.121613e+08</td>\n",
       "      <td>0.554050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-05-03</th>\n",
       "      <td>67.49</td>\n",
       "      <td>83.1100</td>\n",
       "      <td>2.4346</td>\n",
       "      <td>0.60</td>\n",
       "      <td>49.28</td>\n",
       "      <td>24.69</td>\n",
       "      <td>13.09</td>\n",
       "      <td>42.435</td>\n",
       "      <td>143.780222</td>\n",
       "      <td>1.123421e+08</td>\n",
       "      <td>0.601028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-05-04</th>\n",
       "      <td>68.19</td>\n",
       "      <td>83.2300</td>\n",
       "      <td>2.4006</td>\n",
       "      <td>0.60</td>\n",
       "      <td>48.30</td>\n",
       "      <td>24.60</td>\n",
       "      <td>12.91</td>\n",
       "      <td>42.595</td>\n",
       "      <td>143.905111</td>\n",
       "      <td>1.128853e+08</td>\n",
       "      <td>0.665987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CLOSE_GLD  CLOSE_FXY  CLOSE_T10Y2Y  CLOSE_TED  CLOSE_USO  \\\n",
       "Dates                                                                  \n",
       "2007-04-27      67.56    83.7300        2.4474       0.55      51.84   \n",
       "2007-04-30      67.09    83.7166        2.4361       0.57      51.24   \n",
       "2007-05-02      66.66    83.3800        2.4366       0.59      49.59   \n",
       "2007-05-03      67.49    83.1100        2.4346       0.60      49.28   \n",
       "2007-05-04      68.19    83.2300        2.4006       0.60      48.30   \n",
       "\n",
       "            CLOSE_UUP  CLOSE_VIX  CLOSE_VWO       MA_45        VMA_45  \\\n",
       "Dates                                                                   \n",
       "2007-04-27      24.54      12.45     41.750  143.551556  1.106696e+08   \n",
       "2007-04-30      24.49      14.22     40.935  143.601556  1.116466e+08   \n",
       "2007-05-02      24.66      13.08     42.020  143.680667  1.121613e+08   \n",
       "2007-05-03      24.69      13.09     42.435  143.780222  1.123421e+08   \n",
       "2007-05-04      24.60      12.91     42.595  143.905111  1.128853e+08   \n",
       "\n",
       "              RSI_14  \n",
       "Dates                 \n",
       "2007-04-27  0.670018  \n",
       "2007-04-30  0.531751  \n",
       "2007-05-02  0.554050  \n",
       "2007-05-03  0.601028  \n",
       "2007-05-04  0.665987  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"지표 추가, 인덱스 설정, 결측치 제거, 일별 수익률 계산\"\"\"\n",
    "\n",
    "df = moving_average(df, 45)\n",
    "df = volume_moving_average(df, 45)\n",
    "df = relative_strength_index(df, 14)\n",
    "\n",
    "df = df.set_index('Dates')\n",
    "df = df.dropna()\n",
    "\n",
    "df['target'] = df['CLOSE_SPY'].pct_change()\n",
    "df['target'] = np.where(df['target'] > 0, 1, -1)   # 오른 날은 1, 내린 날은 -1로 만들어줌\n",
    "# df['target'] = df.apply(lambda x: 1 if df['target'] > 0 else -1, axis=1)\n",
    "\n",
    "df['target'] = df['target'].shift(-1)   # 당일까지의 데이터로 다음날을 예측해야 하기 때문에 한칸씩 앞으로 당겨줌\n",
    "df = df.dropna()\n",
    "\n",
    "df['target'] = df['target'].astype(np.int64)   # 정수 처리\n",
    "y_var = df['target']\n",
    "x_var = df.drop(['target', 'OPEN', 'HIGH', 'LOW', 'VOLUME', 'CLOSE_SPY'], axis=1)\n",
    "x_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set label ratio\n",
      " 1    0.543501\n",
      "-1    0.456499\n",
      "Name: target, dtype: float64\n",
      "test set label ratio\n",
      " 1    0.530562\n",
      "-1    0.469438\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"훈련셋, 테스트셋 나누기\"\"\"\n",
    "\n",
    "# 기간이 섞이면 안되니 순차적으로 split할 수 있게 shuffle=False로 둔다\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_var, y_var, test_size=0.3, shuffle=False, random_state=3)\n",
    "\n",
    "# 양성, 음성 샘플 비율 \n",
    "train_count = y_train.count()\n",
    "test_count = y_test.count()\n",
    "\n",
    "print('train set label ratio')\n",
    "print(y_train.value_counts() / train_count)\n",
    "print('test set label ratio')\n",
    "print(y_test.value_counts() / test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"혼동 행렬을 계산하는 함수(오차 행렬)\"\"\"\n",
    "\n",
    "def get_confusion_matrix(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_score = roc_auc_score(y_test, pred)\n",
    "    print('confusion matrix')\n",
    "    print('accuracy: {}, precision: {}, recall: {}, F1: {}, ROC AUC score: {}'.format(accuracy, precision, recall, f1, roc_score) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8763102725366876\n",
      "confusion matrix\n",
      "accuracy: 0.49144254278728605, precision: 0.5241935483870968, recall: 0.44930875576036866, F1: 0.4838709677419355, ROC AUC score: 0.4941856278801844\n"
     ]
    }
   ],
   "source": [
    "# xgboost 분류기를 활용하여 모델 만들기\n",
    "xgb_dis = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb_dis.fit(X_train, y_train)\n",
    "xgb_pred = xgb_dis.predict(X_test)\n",
    "print(xgb_dis.score(X_train, y_train))\n",
    "get_confusion_matrix(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter:  {'bootstrap': True, 'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 20}\n",
      "best prediction:  0.5616352201257863\n",
      "confusion matrix\n",
      "accuracy: 0.4743276283618582, precision: 0.5135135135135135, recall: 0.17511520737327188, F1: 0.26116838487972505, ROC AUC score: 0.4938076036866359\n"
     ]
    }
   ],
   "source": [
    "# Grid Search를 통해 다양한 파라미터들을 테스트한다\n",
    "n_estimators = range(10, 30, 10)\n",
    "params = {\n",
    "    'bootstrap': [True],\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': [4,6,8],\n",
    "    'min_samples_leaf': [2,3],\n",
    "    'min_samples_split': [2,4,6],\n",
    "    'max_features': [4]\n",
    "}\n",
    "\n",
    "my_cv = TimeSeriesSplit(n_splits=5).split(X_train)\n",
    "clf = GridSearchCV(RandomForestClassifier(), params, cv=my_cv, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('best parameter: ', clf.best_params_)   # 최적의 파라미터\n",
    "print('best prediction: ', clf.best_score_)   # 가장 높은 정확도\n",
    "\n",
    "# 테스트셋에서의 결과\n",
    "pred_con = clf.predict(X_test)\n",
    "get_confusion_matrix(y_test, pred_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    1375\n",
       "-1.0    1351\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"0.05% 이상의 수익률을 얻었을 때만 상승했다고 보고 'target'값을 업데이트 한다.\"\"\"\n",
    "\n",
    "df_new = pd.read_csv('../data/ETFs_main.csv')\n",
    "df_new = moving_average(df_new, 45)\n",
    "df_new = volume_moving_average(df_new, 45)\n",
    "df_new = relative_strength_index(df_new, 14)\n",
    "df_new = df_new.set_index('Dates')\n",
    "df_new = df_new.dropna()\n",
    "\n",
    "df_new['target'] = df_new['CLOSE_SPY'].pct_change()\n",
    "df_new['target'] = np.where(df_new['target'] > 0.0005, 1, -1)   \n",
    "\n",
    "\n",
    "df_new['target'] = df_new['target'].shift(-1)   \n",
    "df_new = df_new.dropna()\n",
    "df_new['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter:  {'bootstrap': True, 'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "best prediction:  0.5333333333333333\n",
      "confusion matrix\n",
      "accuracy: 0.5122249388753056, precision: 0.5095541401273885, recall: 0.19900497512437812, F1: 0.2862254025044723, ROC AUC score: 0.5069544106391122\n"
     ]
    }
   ],
   "source": [
    "# 그리고 다시 모델 훈련\n",
    "df_new['target'] = df_new['target'].astype(np.int64) \n",
    "y_var = df_new['target']\n",
    "x_var = df_new.drop(['target', 'OPEN', 'HIGH', 'LOW', 'VOLUME', 'CLOSE_SPY'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_var, y_var, test_size=0.3, shuffle=False, random_state=3)\n",
    "\n",
    "my_cv = TimeSeriesSplit(n_splits=5).split(X_train)\n",
    "clf = GridSearchCV(RandomForestClassifier(), params, cv=my_cv, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print('best parameter: ', clf.best_params_)  \n",
    "print('best prediction: ', clf.best_score_)   \n",
    "\n",
    "# 테스트셋에서의 결과\n",
    "pred_con = clf.predict(X_test)\n",
    "get_confusion_matrix(y_test, pred_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tens_2]",
   "language": "python",
   "name": "conda-env-tens_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
